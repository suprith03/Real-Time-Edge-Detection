# Real-Time Edge Detection

A **cross-platform edge detection project** built using **Android (Camera2 + OpenCV + OpenGL ES)** and a **Web (TypeScript) viewer**.
This app captures real-time camera frames, processes them using OpenCVâ€™s C++ library through JNI, and renders the output using OpenGL for smooth visualization.
The web interface allows visualizing processed frames and performance metrics.

---

## ğŸš€ Features

### ğŸ“± Android Application

* Real-time camera capture using **Camera2 API**.
* Native frame processing via **C++ and OpenCV** for high performance.
* Live toggle between **Grayscale** and **Canny Edge Detection** modes.
* Smooth rendering using **OpenGL ES 2.0**.
* FPS and resolution overlay for performance insights.

### ğŸŒ Web Viewer (TypeScript)

* Displays a processed image from the Android app in a **canvas** element.
* Shows **FPS** and **resolution** dynamically.
* Minimal responsive interface using TypeScript + HTML5.

---

## ğŸ§© Project Structure

```
Real-Time-Edge-Detection/
â”‚
â”œâ”€â”€ README.md
â”œâ”€â”€ .gitignore
â”œâ”€â”€ build.gradle
â”œâ”€â”€ gradle.properties
â”œâ”€â”€ settings.gradle
â”œâ”€â”€ gradlew / gradlew.bat
â”‚
â”œâ”€â”€ OpenCV-android-sdk/               # OpenCV SDK 
â”‚
â”œâ”€â”€ app/                              # Android module
â”‚   â”œâ”€â”€ build.gradle
â”‚   â”œâ”€â”€ CMakeLists.txt
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â””â”€â”€ main/
â”‚   â”‚       â”œâ”€â”€ AndroidManifest.xml
â”‚   â”‚       â”œâ”€â”€ java/com/example/edgedetect/
â”‚   â”‚       â”‚   â”œâ”€â”€ MainActivity.kt
â”‚   â”‚       â”‚   â”œâ”€â”€ Camera2Fragment.kt
â”‚   â”‚       â”‚   â”œâ”€â”€ NativeBridge.kt
â”‚   â”‚       â”‚   â””â”€â”€ GLRenderer.kt
â”‚   â”‚       â”œâ”€â”€ cpp/
â”‚   â”‚       â”‚   â”œâ”€â”€ CMakeLists.txt
â”‚   â”‚       â”‚   â””â”€â”€ native-lib.cpp
â”‚   â”‚       â””â”€â”€ res/layout/
â”‚   â”‚           â”œâ”€â”€ activity_main.xml
â”‚   â”‚           â””â”€â”€ fragment_camera2.xml
â”‚
â”œâ”€â”€ jni/                              # Optional external JNI C++
â”‚   â”œâ”€â”€ CMakeLists.txt
â”‚   â””â”€â”€ native-lib.cpp
â”‚
â”œâ”€â”€ web/                              # Web viewer
â”‚   â”œâ”€â”€ index.html
â”‚   â”œâ”€â”€ src/main.ts
â”‚   â”œâ”€â”€ package.json
â”‚   â”œâ”€â”€ tsconfig.json
â”‚   â””â”€â”€ dist/main.js
â”‚
â”œâ”€â”€ docs/                             # Project documentation
â”‚   â”œâ”€â”€ images/
â”‚   â”‚   â”œâ”€â”€ screenshot1.png
â”‚   â”‚   â”œâ”€â”€ screenshot2.png
â”‚   â”‚   â””â”€â”€ ui_layout.png
â”‚   â”œâ”€â”€ gifs/
â”‚   â”‚   â”œâ”€â”€ demo_edge.gif
â”‚   â”‚   â””â”€â”€ real_time_processing.gif
â”‚   â””â”€â”€ architecture_diagram.png
â”‚
â””â”€â”€ LICENSE
```

---

## ğŸ“¸ Screenshots & Demos

### Android App

| Edge Detection Mode                       |
| ----------------------------------------- |
| ![Edge Mode](docs/images/screenshot1.png) |

### ğŸ Real-Time Demo

![Real-Time Edge Detection](docs/gifs/demo_edge.gif)

---

## ğŸ› ï¸ Setup Instructions

### Prerequisites

* **Android Studio** (with NDK & CMake)
* **Android NDK** (r21 or newer)
* **OpenCV Android SDK**
* **Node.js + npm** (for web viewer)

---

### âš™ï¸ Android Setup

1. **Install NDK & CMake**

   * Open *Android Studio â†’ Preferences â†’ SDK Tools*
   * Enable *NDK* and *CMake* installation.

2. **Add OpenCV SDK**

   * Download OpenCV Android SDK (e.g., `opencv-4.x-android-sdk`).
   * Place it in the project root or reference it globally.
   * Update your `CMakeLists.txt`:

     ```cmake
     set(OpenCV_DIR ${CMAKE_SOURCE_DIR}/../OpenCV-android-sdk/sdk/native/jni)
     find_package(OpenCV REQUIRED)
     include_directories(${OpenCV_INCLUDE_DIRS})
     target_link_libraries(native-lib ${OpenCV_LIBS} log)
     ```

3. **Permissions**

   * Add these to `AndroidManifest.xml`:

     ```xml
     <uses-permission android:name="android.permission.CAMERA" />
     <uses-permission android:name="android.permission.WRITE_EXTERNAL_STORAGE" />
     ```

4. **Build & Run**

   * Connect a physical Android device.
   * Run the project from Android Studio.
   * Switch between **Edge** and **Grayscale** modes using the toggle button.

---

### ğŸŒ Web Viewer Setup

1. Open a terminal and navigate to `/web`:

   ```bash
   cd web
   npm install
   ```
2. Build the TypeScript project:

   ```bash
   npm run build
   ```
3. Open `index.html` in a browser, or serve locally:

   ```bash
   npx live-server
   ```
4. Replace the placeholder `base64Image` in `src/main.ts` with an exported base64 image from your Android app.

---

## ğŸ’¡ How It Works

1. The **Camera2 API** captures each frame (YUV format).
2. Frames are sent via **JNI** to **C++ OpenCV** for processing.
3. OpenCV applies **Grayscale** or **Canny Edge Detection**.
4. Processed RGBA frames are returned to Kotlin and rendered via **OpenGL ES 2.0**.
5. The **Web Viewer** displays static processed images and performance overlays.

---

## ğŸ“ˆ Performance Notes

* Real-time processing achieved using **NDK + OpenCV C++**.
* **OpenGL ES** ensures smooth texture rendering on device.
* For best FPS, prefer **640Ã—480** camera resolution.
* Edge detection algorithm: *Canny* with thresholds (80, 120).

---

## ğŸ§  Architecture Overview

![System Architecture](docs/architecture_diagram.png)

---

## ğŸ§° Tech Stack

**Android**

* Kotlin
* Camera2 API
* OpenCV (C++)
* OpenGL ES 2.0
* JNI bridge

**Web**

* TypeScript
* HTML5 Canvas
* npm / live-server
ng native C++ speed with modern Android and web technologies to achieve real-time vision performance.â€
